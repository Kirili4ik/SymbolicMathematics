{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kpgelvan/SymbolicMathematics\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import torch\n",
    "\n",
    "from src.utils import AttrDict\n",
    "from src.envs import build_env\n",
    "from src.model import build_modules\n",
    "\n",
    "from src.utils import to_cuda\n",
    "from src.envs.sympy_utils import simplify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build environment / Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def reload_checkpoint(path):\\n    \"\"\"\\n    Reload a checkpoint if we find one.\\n    \"\"\"\\n    checkpoint_path = os.path.join(path, \\'checkpoint.pth\\')\\n    data = torch.load(checkpoint_path, map_location=\\'cpu\\')\\n\\n    # reload model parameters\\n    for k, v in self.modules.items():\\n        v.load_state_dict(data[k])\\n\\n    # reload optimizers\\n    for name in self.optimizers.keys():\\n        # AMP checkpoint reloading is buggy, we cannot reload optimizers\\n        # instead, we only reload current iterations / learning rates\\n        if self.params.amp == -1:\\n            self.optimizers[name].load_state_dict(data[f\\'{name}_optimizer\\'])\\n        else:\\n            for group_id, param_group in enumerate(self.optimizers[name].param_groups):\\n                if \\'num_updates\\' not in param_group:\\n                    logger.warning(f\"No \\'num_updates\\' for optimizer {name}.\")\\n                    continue\\n                logger.warning(f\"Reloading \\'num_updates\\' and \\'lr\\' for optimizer {name}.\")\\n                param_group[\\'num_updates\\'] = data[f\\'{name}_optimizer\\'][\\'param_groups\\'][group_id][\\'num_updates\\']\\n                param_group[\\'lr\\'] = self.optimizers[name].get_lr_for_step(param_group[\\'num_updates\\'])\\n\\n    # reload main metrics\\n    self.epoch = data[\\'epoch\\'] + 1\\n    self.n_total_iter = data[\\'n_total_iter\\']\\n    self.best_metrics = data[\\'best_metrics\\']\\n    self.best_stopping_criterion = data[\\'best_stopping_criterion\\']'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def reload_checkpoint(path):\n",
    "    \"\"\"\n",
    "    Reload a checkpoint if we find one.\n",
    "    \"\"\"\n",
    "    checkpoint_path = os.path.join(path, 'checkpoint.pth')\n",
    "    data = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    # reload model parameters\n",
    "    for k, v in self.modules.items():\n",
    "        v.load_state_dict(data[k])\n",
    "\n",
    "    # reload optimizers\n",
    "    for name in self.optimizers.keys():\n",
    "        # AMP checkpoint reloading is buggy, we cannot reload optimizers\n",
    "        # instead, we only reload current iterations / learning rates\n",
    "        if self.params.amp == -1:\n",
    "            self.optimizers[name].load_state_dict(data[f'{name}_optimizer'])\n",
    "        else:\n",
    "            for group_id, param_group in enumerate(self.optimizers[name].param_groups):\n",
    "                if 'num_updates' not in param_group:\n",
    "                    logger.warning(f\"No 'num_updates' for optimizer {name}.\")\n",
    "                    continue\n",
    "                logger.warning(f\"Reloading 'num_updates' and 'lr' for optimizer {name}.\")\n",
    "                param_group['num_updates'] = data[f'{name}_optimizer']['param_groups'][group_id]['num_updates']\n",
    "                param_group['lr'] = self.optimizers[name].get_lr_for_step(param_group['num_updates'])\n",
    "\n",
    "    # reload main metrics\n",
    "    self.epoch = data['epoch'] + 1\n",
    "    self.n_total_iter = data['n_total_iter']\n",
    "    self.best_metrics = data['best_metrics']\n",
    "    self.best_stopping_criterion = data['best_stopping_criterion']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model, e.g. \"wget https://dl.fbaipublicfiles.com/SymbolicMathematics/models/fwd_bwd.pth\"\n",
    "#model_path = 'fwd.pth'\n",
    "model_path = 'dumped/seq_rel_att_0202/272202/checkpoint.pth'\n",
    "assert os.path.isfile(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params = AttrDict({\n",
    "\n",
    "    # environment parameters\n",
    "    'env_name': 'char_sp',\n",
    "    'int_base': 10,\n",
    "    'balanced': False,\n",
    "    'positive': True,\n",
    "    'precision': 10,\n",
    "    'n_variables': 1,\n",
    "    'n_coefficients': 0,\n",
    "    'leaf_probs': '0.75,0,0.25,0',\n",
    "    'max_len': 512,\n",
    "    'max_int': 5,\n",
    "    'max_ops': 15,\n",
    "    'max_ops_G': 15,\n",
    "    'clean_prefix_expr': True,\n",
    "    'rewrite_functions': '',\n",
    "    'tasks': 'prim_fwd',\n",
    "    'operators': 'add:10,sub:3,mul:10,div:5,sqrt:4,pow2:4,pow3:2,pow4:1,pow5:1,ln:4,exp:4,sin:4,cos:4,tan:4,asin:1,acos:1,atan:1,sinh:1,cosh:1,tanh:1,asinh:1,acosh:1,atanh:1',\n",
    "\n",
    "    'max_relative_pos':250,\n",
    "    'use_neg_dist':True,\n",
    "    'use_encdec_seq_rel_att':False,\n",
    "    'max_path_width':-1,\n",
    "    'max_path_depth':-1,\n",
    "    'use_tree_pos_enc_E':False,\n",
    "    'use_tree_pos_enc_D':False,\n",
    "    'use_tree_rel_att':\"\",\n",
    "    'tree_rel_vocab_size':0,\n",
    "    'use_pos_embeddings_E':False,\n",
    "    'use_pos_embeddings_D':False,\n",
    "    \n",
    "    # model parameters\n",
    "    'cpu': True,\n",
    "    'emb_dim': 256,\n",
    "    'n_enc_layers': 4,\n",
    "    'n_dec_layers': 4,\n",
    "    'n_heads': 4,\n",
    "    'dropout': 0,\n",
    "    'attention_dropout': 0,\n",
    "    'sinusoidal_embeddings': False,\n",
    "    'share_inout_emb': True,\n",
    "    'reload_model': model_path,\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = build_env(params)\n",
    "x = env.local_dict['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = build_modules(env, params)\n",
    "encoder = modules['encoder']\n",
    "decoder = modules['decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0739, -0.2999,  0.2414,  ..., -0.0033,  0.1309,  0.2013],\n",
       "        [-0.1916, -0.0242,  0.0273,  ..., -0.1218,  0.0545,  0.2007],\n",
       "        [-0.1722, -0.0376,  0.0310,  ..., -0.1337,  0.0441,  0.1990],\n",
       "        ...,\n",
       "        [-0.1476, -0.0959,  0.1432,  ...,  0.0296,  0.0949, -0.2183],\n",
       "        [ 0.0864, -0.0371, -0.0220,  ..., -0.1343,  0.1126, -0.1488],\n",
       "        [ 0.0472, -0.0501, -0.0385,  ...,  0.2324,  0.0864, -0.1636]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0739, -0.2999,  0.2414,  ..., -0.0033,  0.1309,  0.2013],\n",
       "        [-0.1916, -0.0242,  0.0273,  ..., -0.1218,  0.0545,  0.2007],\n",
       "        [-0.1722, -0.0376,  0.0310,  ..., -0.1337,  0.0441,  0.1990],\n",
       "        ...,\n",
       "        [-0.1476, -0.0959,  0.1432,  ...,  0.0296,  0.0949, -0.2183],\n",
       "        [ 0.0864, -0.0371, -0.0220,  ..., -0.1343,  0.1126, -0.1488],\n",
       "        [ 0.0472, -0.0501, -0.0385,  ...,  0.2324,  0.0864, -0.1636]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.embeddings.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from a function F, compute its derivative f = F', and try to recover F from f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can modify the integral function the model has to predict, F\n",
    "F_infix = 'x * tan(exp(x)/x)'\n",
    "#F_infix = 'x * cos(x**2) * tan(x)'\n",
    "#F_infix = 'cos(x**2 * exp(x * cos(x)))'\n",
    "#F_infix = 'ln(cos(x + exp(x)) * sin(x**2 + 2) * exp(x) / x)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x \\tan{\\left(\\frac{e^{x}}{x} \\right)}$"
      ],
      "text/plain": [
       "x*tan(exp(x)/x)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F (integral, that the model will try to predict)\n",
    "F = sp.S(F_infix, locals=env.local_dict)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x \\left(\\frac{e^{x}}{x} - \\frac{e^{x}}{x^{2}}\\right) \\left(\\tan^{2}{\\left(\\frac{e^{x}}{x} \\right)} + 1\\right) + \\tan{\\left(\\frac{e^{x}}{x} \\right)}$"
      ],
      "text/plain": [
       "x*(exp(x)/x - exp(x)/x**2)*(tan(exp(x)/x)**2 + 1) + tan(exp(x)/x)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f (F', that the model will take as input)\n",
    "f = F.diff(x)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute prefix representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F prefix: ['mul', 'x', 'tan', 'mul', 'pow', 'x', 'INT-', '1', 'exp', 'x']\n",
      "f prefix: ['add', 'mul', 'x', 'mul', 'add', 'INT+', '1', 'pow', 'tan', 'mul', 'pow', 'x', 'INT-', '1', 'exp', 'x', 'INT+', '2', 'add', 'mul', 'pow', 'x', 'INT-', '1', 'exp', 'x', 'mul', 'INT-', '1', 'mul', 'pow', 'x', 'INT-', '2', 'exp', 'x', 'tan', 'mul', 'pow', 'x', 'INT-', '1', 'exp', 'x']\n"
     ]
    }
   ],
   "source": [
    "F_prefix = env.sympy_to_prefix(F)\n",
    "f_prefix = env.sympy_to_prefix(f)\n",
    "print(f\"F prefix: {F_prefix}\")\n",
    "print(f\"f prefix: {f_prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_prefix = env.clean_prefix(['sub', 'derivative', 'f', 'x', 'x'] + f_prefix)\n",
    "x1 = torch.LongTensor(\n",
    "    [env.eos_index] +\n",
    "    [env.word2id[w] for w in x1_prefix] +\n",
    "    [env.eos_index]\n",
    ").view(-1, 1)\n",
    "len1 = torch.LongTensor([len(x1)])\n",
    "x1, len1 = to_cuda(x1, len1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded = encoder('fwd', x=x1, lengths=len1, causal=False).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode with beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 100\n",
    "with torch.no_grad():\n",
    "    _, _, beam = decoder.generate_beam(encoded, len1, beam_size=beam_size, length_penalty=1.0, early_stopping=1, max_len=200)\n",
    "    assert len(beam) == 1\n",
    "hypotheses = beam[0].hyp\n",
    "assert len(hypotheses) == beam_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input function f: x*(exp(x)/x - exp(x)/x**2)*(tan(exp(x)/x)**2 + 1) + tan(exp(x)/x)\n",
      "Reference function F: x*tan(exp(x)/x)\n",
      "\n",
      "-0.18937  NO  0\n",
      "-0.19152  NO  exp(x)\n",
      "-0.19262  NO  x*tan(exp(x)/x) - exp(x)\n",
      "-0.20441  NO  x*tan(exp(x)/x) + exp(x)\n",
      "-0.20617  OK  x*tan(exp(x)/x)\n",
      "-0.20694  NO  x*tan(exp(x)/x) - exp(2*x)/2 - exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.20715  NO  exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.20731  NO  -2*exp(x) + log(tan(exp(x)/x)**2 + 1)/2 - tan(exp(x)/x)\n",
      "-0.20772  NO  -exp(2*x)/2 - exp(x)*tan(exp(x)/x) - exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.20893  NO  -x*tan(exp(x)/x) + exp(x)\n",
      "-0.20930  NO  -exp(x)\n",
      "-0.21063  NO  x*tan(exp(x)/x) - exp(2*x)/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21140  NO  x*tan(exp(x)/x) - exp(2*x)/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21171  NO  x*tan(exp(x)/x) - 2*exp(x)\n",
      "-0.21290  NO  -x*tan(exp(x)/x) - exp(2*x)/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21479  NO  -x*tan(exp(x)/x) - exp(2*x)/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21501  NO  -exp(x)*tan(exp(x)/x) + exp(x)\n",
      "-0.21721  NO  -exp(2*x)/2 + exp(x)*tan(exp(x)/x)/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21799  NO  x*tan(exp(x)/x)**2 - x*tan(exp(x)/x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21850  NO  -exp(2*x)/2 + exp(x)*tan(exp(x)/x)**2/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21885  NO  x*tan(exp(x)/x) - exp(2*x) + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21941  NO  -log(-exp(2*x) + tan(exp(x)/x))/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.21959  NO  -log(x)\n",
      "-0.21997  NO  x*tan(exp(x)/x) - exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22039  NO  x*tan(exp(x)/x) + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22068  NO  x*tan(exp(x)/x) + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22135  NO  -exp(2*x)/2 + exp(x)*tan(exp(x)/x)/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22318  NO  -exp(x)\n",
      "-0.22377  NO  x*tan(exp(x)/x)**2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22436  NO  x*tan(exp(x)/x)**2 - exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22505  NO  x*tan(exp(x)/x)**2 - exp(2*x)/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22647  NO  log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22669  NO  -2*exp(x)\n",
      "-0.22705  NO  -exp(2*x)/2 - exp(x)*tan(exp(x)/x) + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22710  NO  exp(2*x)*tan(exp(x)/x)**2/2 - exp(2*x)/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22779  NO  log(tan(exp(x)/x)**2 + 1)/2 - tan(exp(x)/x)\n",
      "-0.22785  NO  x*tan(exp(x)/x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22826  NO  x*tan(exp(x)/x) - exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22835  NO  -2*exp(x) + log(tan(exp(x)/x)**2 + 1)\n",
      "-0.22858  NO  -exp(x) + log(x)\n",
      "-0.22893  NO  log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.22994  NO  -exp(2*x)/2 - exp(x)*tan(exp(x)/x)**2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23062  NO  -exp(x) + log(tan(exp(x)/x)**2 + 1)/2 - tan(exp(x)/x)\n",
      "-0.23070  NO  exp(x)*tan(exp(x)/x)**2/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23120  NO  -2*exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23154  NO  exp(x) - log(-exp(2*x) + tan(exp(x)/x))/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23181  INVALID PREFIX EXPRESSION  ['add', 'mul', 'div', 'INT+', '1', 'INT+', '2', 'ln', 'add', 'INT+', '1', 'pow', 'tan', 'mul', 'pow', 'x', 'INT-', '1', 'exp', 'x', 'INT+', '2', 'add', 'mul', 'INT-', '1', 'exp', 'x', 'add', 'mul', 'INT-', '1', 'exp', 'x', 'add', 'mul', 'div', 'INT-', '1', 'INT+', '2', 'ln', 'add', 'INT+', '1', 'pow', 'tan', 'mul', 'pow', 'x', 'INT-', '1', 'exp', 'x', 'INT+', '2', 'ln', 'x']\n",
      "-0.23193  NO  log(tan(exp(x)/x)**2 + 1)\n",
      "-0.23287  NO  exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23336  NO  exp(2*x)/2 - 2*exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23398  NO  exp(2*x)/2 + exp(x)*tan(exp(x)/x)**2/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23402  NO  exp(2*x)/2 + exp(x)*tan(exp(x)/x)/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23527  NO  x*tan(exp(x)/x) - 2*exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23569  NO  -exp(2*x)/2 - exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23608  NO  -log(tan(exp(x)/x) + 1)/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23646  NO  exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23652  NO  -exp(2*x)/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23724  NO  exp(x)*tan(exp(x)/x)/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23771  NO  exp(x) + log(tan(exp(x)/x)**2 + 1)\n",
      "-0.23829  NO  log(tan(exp(x)/x)**2 + 1)/2 + zoo\n",
      "-0.23880  NO  -exp(2*x)/2 + exp(x)*tan(exp(x)/x)**2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.23918  NO  x*tan(exp(x)/x) - exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.24001  NO  exp(2*x)/2 - exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.24065  NO  -exp(x) + log(tan(exp(x)/x)**2 + 1)\n",
      "-0.24241  NO  -exp(x) - log(exp(2*x) + 1)/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.24272  NO  exp(2*x)/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.24294  NO  exp(2*x)/2 - exp(x) - log(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.24314  NO  exp(x) + log(tan(exp(x)/x)**2 + 1)/2 + tan(exp(x)/x)**2/2\n",
      "-0.24379  NO  -2*exp(x) + log(tan(exp(x)/x)**2 + 1)/2 - tan(exp(x)/x)\n",
      "-0.24431  NO  -exp(2*x)/2 + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.24709  NO  exp(x) + log(tan(exp(x)/x)**2 + 1)/2 + tan(exp(x)/x)\n",
      "-0.24731  NO  exp(2*x)/2 + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.24787  NO  -exp(x) - log(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.24931  NO  -2*exp(x) - log(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.25059  NO  -exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.25114  NO  -log(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.25116  NO  -3*exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.25158  NO  -x*tan(exp(x)/x) + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.25187  NO  x*tan(exp(x)/x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.25347  NO  -exp(x)*tan(exp(x)/x) + exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.26644  NO  -exp(x) + log(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.26941  NO  -log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.27319  NO  -exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.28326  NO  log(tan(exp(x)/x)**2 + 1)/2 + exp(-x)\n",
      "-0.29360  NO  -2*exp(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.30362  NO  exp(x) + log(tan(exp(2)/x)**2 + 1)/2\n",
      "-0.32153  NO  exp(x) - log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.32788  NO  log(x) + log(tan(exp(x)/x)**2 + 1)/2\n",
      "-0.35835  NO  exp(x) + log(tan(exp(x))**2 + 1)/2\n",
      "-0.37457  NO  exp(x) + tan(exp(x)/x)**2/2\n",
      "-1.03111  NO  -exp(x)\n",
      "-1.19371  NO  exp(x) - 1\n",
      "-1.55713  NO  exp(x)\n",
      "-2.65636  INVALID PREFIX EXPRESSION  ['INT-', 'add']\n",
      "-3.36859  NO  x\n",
      "-4.07332  NO  0\n",
      "-4.35444  INVALID PREFIX EXPRESSION  ['add']\n",
      "-4.47972  NO  0\n",
      "-4.69680  NO  E\n",
      "-8.58106  INVALID PREFIX EXPRESSION  []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input function f: {f}\")\n",
    "print(f\"Reference function F: {F}\")\n",
    "print(\"\")\n",
    "\n",
    "for score, sent in sorted(hypotheses, key=lambda x: x[0], reverse=True):\n",
    "\n",
    "    # parse decoded hypothesis\n",
    "    ids = sent[1:].tolist()                  # decoded token IDs\n",
    "    tok = [env.id2word[wid] for wid in ids]  # convert to prefix\n",
    "\n",
    "    try:\n",
    "        hyp = env.prefix_to_infix(tok)       # convert to infix\n",
    "        hyp = env.infix_to_sympy(hyp)        # convert to SymPy\n",
    "\n",
    "        # check whether we recover f if we differentiate the hypothesis\n",
    "        # note that sometimes, SymPy fails to show that hyp' - f == 0, and the result is considered as invalid, although it may be correct\n",
    "        res = \"OK\" if simplify(hyp.diff(x) - f, seconds=1) == 0 else \"NO\"\n",
    "\n",
    "    except:\n",
    "        res = \"INVALID PREFIX EXPRESSION\"\n",
    "        hyp = tok\n",
    "\n",
    "    # print result\n",
    "    print(\"%.5f  %s  %s\" % (score, res, hyp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
